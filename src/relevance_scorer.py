"""
Enhanced Relevance Scorer - Optimized for Target Output
"""

import numpy as np
from typing import List, Dict, Any, Tuple

class RelevanceScorer:
    def __init__(self, semantic_analyzer):
        self.semantic_analyzer = semantic_analyzer
        
        # Optimized weights for target output
        self.weights = {
            'exact_job_match': 0.35,      # Highest weight for job correlation
            'critical_keywords': 0.25,    # Critical planning keywords
            'semantic_similarity': 0.20,   # Semantic understanding
            'actionable_content': 0.10,    # Actionable information
            'section_quality': 0.05,      # Section quality
            'practical_value': 0.05       # Practical value
        }
    
    def score_all_sections(self, sections: List[Dict[str, Any]], 
                          persona: str, job_description: str) -> List[Tuple[Dict[str, Any], float]]:
        """Score sections for target output accuracy"""
        
        print(f"ðŸŽ¯ Scoring {len(sections)} sections for target accuracy...")
        
        # Analyze requirements
        requirements = self.semantic_analyzer.analyze_persona_requirements(
            persona, job_description
        )
        
        scored_sections = []
        
        for section in sections:
            # Calculate relevance scores
            relevance_scores = self.semantic_analyzer.calculate_enhanced_relevance(
                section, requirements
            )
            
            # Calculate weighted final score
            final_score = self._calculate_weighted_score(relevance_scores)
            
            # Apply target-specific adjustments
            final_score = self._apply_target_adjustments(
                final_score, section, requirements
            )
            
            scored_sections.append((section, final_score, {
                'exact_job_match': relevance_scores.get('exact_job_match', 0),
                'critical_keywords': relevance_scores.get('critical_keywords', 0),
                'semantic_similarity': relevance_scores.get('semantic_similarity', 0),
                'actionable_content': relevance_scores.get('actionable_content', 0),
                'final_score': final_score
            }))
        
        # Sort by score (highest first)
        scored_sections.sort(key=lambda x: x[1], reverse=True)
        
        print(f"âœ… Scored sections - Top score: {scored_sections[0][1]:.3f}")
        return scored_sections
    
    def _calculate_weighted_score(self, scores: Dict[str, float]) -> float:
        """Calculate weighted final score"""
        total_score = 0.0
        
        for factor, weight in self.weights.items():
            score = scores.get(factor, 0.0)
            total_score += weight * score
        
        return total_score
    
    def _apply_target_adjustments(self, base_score: float, section: Dict[str, Any], 
                                requirements: Dict[str, Any]) -> float:
        """Apply adjustments for target output quality"""
        
        adjusted_score = base_score
        content = section.get('content', '').lower()
        title = section.get('title', '').lower()
        
        # Heavy boost for job-specific content
        job_analysis = requirements['job_analysis']
        
        if job_analysis['duration'] and job_analysis['duration'].lower() in content:
            adjusted_score *= 1.5  # 50% boost
        
        if job_analysis['group_size'] and str(job_analysis['group_size']) in content:
            adjusted_score *= 1.4  # 40% boost
        
        if job_analysis['group_type'] and job_analysis['group_type'].lower() in content:
            adjusted_score *= 1.3  # 30% boost
        
        # Boost for planning-related titles
        planning_terms = ['planning', 'itinerary', 'guide', 'tips', 'organize']
        if any(term in title for term in planning_terms):
            adjusted_score *= 1.2  # 20% boost
        
        # Heavy penalty for generic introductory content
        generic_terms = ['introduction', 'overview', 'welcome', 'about', 'general']
        if any(term in title or term in content[:100] for term in generic_terms):
            adjusted_score *= 0.3  # 70% penalty
        
        # Penalty for sentence fragments as titles
        if len(title) > 80 or title.count(',') > 2:
            adjusted_score *= 0.5  # 50% penalty
        
        # Boost for university/college content (matches job requirement)
        if any(term in content for term in ['university', 'college', 'student', 'montpellier']):
            adjusted_score *= 1.15  # 15% boost
        
        return max(0.0, adjusted_score)
    
    def get_top_sections_for_target_output(self, scored_sections: List[Tuple], 
                                         top_k: int = 7) -> List[Dict[str, Any]]:
        """Get top sections formatted for target output"""
        
        top_sections = []
        
        for i, (section, score, details) in enumerate(scored_sections[:top_k]):
            top_sections.append({
                'document': section['document'],
                'section_title': section['title'],
                'importance_rank': i + 1,
                'page_number': section['page_number'],
                'content': section['content'],
                'relevance_score': score,
                'score_details': details
            })
        
        # Print ranking for verification
        print(f"ðŸ“Š Target Output Ranking:")
        for section in top_sections:
            print(f"  {section['importance_rank']}. {section['section_title'][:70]}...")
            print(f"     ðŸ“„ {section['document']} (Score: {section['relevance_score']:.3f})")
        
        return top_sections
